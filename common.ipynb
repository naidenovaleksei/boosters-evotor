{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"source/evo_train.csv\"\n",
    "PATH_TEST = \"source/evo_test.csv\"\n",
    "PATH_CATS = \"source/categories.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_label = u'GROUP_ID'\n",
    "pred_labels = u'NAME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = pd.read_csv(PATH_TRAIN)\n",
    "dtest = pd.read_csv(PATH_TEST)\n",
    "cats = pd.read_csv(PATH_CATS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = dtrain[target_label]\n",
    "preds = dtrain[pred_labels]\n",
    "preds_test = dtest[pred_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    preds, target, \n",
    "    test_size=0.33, \n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def check_accuracy(clf, x, y, x_test, y_test):\n",
    "    clf.fit(x, y)\n",
    "    t = clf.predict(x_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print \"accuracy_score: %f\" % accuracy_score(y_test, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.812249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "baseline_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB())])\n",
    "check_accuracy(baseline_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.930889\n"
     ]
    }
   ],
   "source": [
    "# SelectFromModel\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "clf_v5 = Pipeline([('vect', CountVectorizer()),\n",
    "#                    ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                   ('select', SelectFromModel(LogisticRegression(C=0.01, penalty=\"l2\", dual=False), \n",
    "                                              threshold=\"0.01*mean\")),\n",
    "                   ('clf', SGDClassifier(loss='hinge', \n",
    "                                         penalty='l2',\n",
    "                                         alpha=1e-4, \n",
    "                                         n_iter=50, \n",
    "                                         random_state=42))\n",
    "                  ])\n",
    "\n",
    "# t = clf_v5.fit_transform(X_train, y_train)\n",
    "check_accuracy(clf_v5, X_train, y_train, X_test, y_test)\n",
    "# print cross_val_score(clf_v5, X_train, y_train, scoring='accuracy', cv=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.930889\n"
     ]
    }
   ],
   "source": [
    "preds_sgd = clf_v5.predict(X_test)\n",
    "print \"accuracy_score: %f\" % accuracy_score(y_test, preds_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25075, 4048)\n"
     ]
    }
   ],
   "source": [
    "# counter = CountVectorizer(min_df=5, binary=True)\n",
    "counter = Pipeline([\n",
    "        ('counter', CountVectorizer(min_df=5, binary=True)),\n",
    "#         ('tfidf', TfidfTransformer(use_idf=False))\n",
    "#         ('tfidf', TfidfTransformer())\n",
    "    ])\n",
    "t = counter.fit_transform(X_train1)\n",
    "print t.shape\n",
    "# vocal = counter.vocabulary_\n",
    "vocal = counter.named_steps['counter'].vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtrain = pd.DataFrame(t.todense())\n",
    "dtrain.columns = pd.Series(vocal).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain[\"target\"] = y_train1.reset_index()[\"GROUP_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m = dtrain[:10000].groupby(\"target\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = dtrain[:int(10e3)].groupby(\"target\").max()\n",
    "m2 = dtrain[int(10e3):int(20e3)].groupby(\"target\").max()\n",
    "m3 = dtrain[int(20e3):int(30e3)].groupby(\"target\").max()\n",
    "m4 = dtrain[int(30e3):].groupby(\"target\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = pd.concat([m1,m2,m3,m4]).reset_index().groupby(\"target\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = counter.transform(X_test1)\n",
    "dtest = pd.DataFrame(tt.todense())\n",
    "dtest.columns = pd.Series(vocal).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.dot(m.as_matrix(), dtest.transpose().as_matrix()).transpose()\n",
    "x = np.dot(m.as_matrix(), dtest.transpose().as_matrix()).transpose()\n",
    "preds_evr = m.index[np.argmax(x, axis=(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_test = dtest.apply(lambda x: sum(x), axis=1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.763582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print \"accuracy_score: %f\" % accuracy_score(y_test1, preds_evr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class HardClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self, min_df=5, binary=True):\n",
    "        self.counter = CountVectorizer(min_df=5, binary=True)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        counter = self.counter\n",
    "        t = counter.fit_transform(X)\n",
    "        self.vocal = counter.vocabulary_\n",
    "        dtrain = pd.DataFrame(t.todense())\n",
    "        dtrain.columns = pd.Series(self.vocal).index\n",
    "        if type(y) == pd.Series:\n",
    "            y = y.reset_index(drop=True)\n",
    "        dtrain[\"target\"] = y\n",
    "        m1 = dtrain[:int(10e3)].groupby(\"target\").max()\n",
    "        m2 = dtrain[int(10e3):int(20e3)].groupby(\"target\").max()\n",
    "        m3 = dtrain[int(20e3):int(30e3)].groupby(\"target\").max()\n",
    "        m4 = dtrain[int(30e3):].groupby(\"target\").max()\n",
    "        self.M = pd.concat([m1,m2,m3,m4]).reset_index().groupby(\"target\").max()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        vocal = self.vocal\n",
    "        m = self.M\n",
    "#         counter = self.counter\n",
    "        counter = CountVectorizer(min_df=5, binary=True, vocabulary=vocal)\n",
    "        tt = counter.fit_transform(X)\n",
    "        dtest = pd.DataFrame(tt.todense())\n",
    "        assert len(m.columns) == len(dtest.columns)\n",
    "        dtest.columns = pd.Series(vocal).index\n",
    "        x = np.dot(m.as_matrix(), dtest.transpose().as_matrix()).transpose()\n",
    "        self.correct = dtest.apply(lambda x: sum(x), axis=1) > 0\n",
    "        return m.index[np.argmax(x, axis=(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.779809\n"
     ]
    }
   ],
   "source": [
    "hard = HardClassifier(min_df=5, binary=True)\n",
    "check_accuracy(hard, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONE more model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_v4 = Pipeline([('vect', CountVectorizer()),\n",
    "                   ('clf', LogisticRegression(C=20000,\n",
    "                                              penalty=\"l2\",\n",
    "                                              n_jobs=4,\n",
    "                                              random_state=17,\n",
    "                                              max_iter=500, \n",
    "#                                               solver='newton-cg',#0.925...\n",
    "                                              solver='liblinear', #0.926169\n",
    "#                                               solver='lbfgs', #0.925030\n",
    "#                                               multi_class='multinomial',#0.923891\n",
    "                                              class_weight='balanced', #0.927254\n",
    "                                              dual=False))\n",
    "                  ])\n",
    "# check_accuracy(clf_v4, X_train, y_train, X_test, y_test)\n",
    "# print cross_val_score(clf_v4, X_train, y_train, scoring='accuracy', cv=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.927254\n"
     ]
    }
   ],
   "source": [
    "preds_lr = clf_v4.predict(X_test)\n",
    "print \"accuracy_score: %f\" % accuracy_score(y_test, preds_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.928176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voter = VotingClassifier([('lr', clf_v4), \n",
    "                          ('sgd', clf_v5), \n",
    "                          ('hard', HardClassifier(min_df=5, binary=True))],\n",
    "                        voting='hard' # 0.926766\n",
    "                        )\n",
    "check_accuracy(voter, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_accuracy.fit(preds, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "#     X_train, y_train, \n",
    "    preds, target,\n",
    "    test_size=0.33, \n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sgd = clf_v5.fit(X_train1, y_train1).predict(X_test1)\n",
    "train_lr = clf_v4.fit(X_train1, y_train1).predict(X_test1)\n",
    "train_hard = hard.fit(X_train1, y_train1).predict(X_test1)\n",
    "\n",
    "dfpreds = pd.DataFrame({\"preds_sgd\": train_sgd, \n",
    "                        \"preds_hard\":train_hard,\n",
    "                        \"preds_lr\": train_lr,\n",
    "                       \"y_test\": y_test1.reset_index(drop=True)})\n",
    "\n",
    "dummy_preds = pd.get_dummies(dfpreds[[\"preds_sgd\", \"preds_hard\", \"preds_lr\"]].astype(str), drop_first=True)\n",
    "dummies = dummy_preds.columns\n",
    "\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2',\n",
    "                    alpha=1e-4, n_iter=50, \n",
    "                    random_state=42)\n",
    "sgd.fit(dummy_preds, dfpreds['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, y_train1, X_test1 = preds, target, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-239-a2974e300de3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdummy_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"preds_sgd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"preds_hard\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"preds_lr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mpred_ensemble\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sgd = clf_v5.fit(X_train1, y_train1).predict(X_test1)\n",
    "train_lr = clf_v4.fit(X_train1, y_train1).predict(X_test1)\n",
    "train_hard = hard.fit(X_train1, y_train1).predict(X_test1)\n",
    "dfpreds = pd.DataFrame({\"preds_sgd\": train_sgd, \n",
    "                        \"preds_hard\":train_hard,\n",
    "                        \"preds_lr\": train_lr})\n",
    "\n",
    "dummy_preds = pd.get_dummies(dfpreds[[\"preds_sgd\", \"preds_hard\", \"preds_lr\"]].astype(str), drop_first=True)\n",
    "\n",
    "assert len(dummy_preds.columns) == len(dummies)\n",
    "\n",
    "pred_ensemble = sgd.predict(dummy_preds)\n",
    "print \"accuracy_score: %f\" % accuracy_score(y_test, pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_ensemble = sgd.predict(dummy_preds[dummies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit = pd.Series(pred_ensemble).reset_index()\n",
    "submit.columns = \"id\",\"GROUP_ID\"\n",
    "submit.to_csv('submit_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
